---
title: "微调模型——续（Machine Learning 研习之十三）"
description: "微调模型——续（Machine Learning 研习之十三）"

lastmod: 2024-03-09T17:45:01+08:00
date: 2024-03-09T17:45:01+08:00


categories:
 - Machine Learning
 - 人工智能
tags: 
 - 机器学习 
 - 人工智能 
 - tensorflow 
 - Mechine Learn 
 - 决策树 
 - 随机森林
comment:
  enable: true
url: article/193
toc: true
#weight: 1


cover:
   image: "https://qiucodeimg.oss-rg-china-mainland.aliyuncs.com/qiucode2020/1710578959569.png" #图片路径例如：posts/tech/123/123.png
   zoom: 50% # 图片大小，例如填写 50% 表示原图像的一半大小
   caption: "微调模型——续（Machine Learning 研习之十三）" #图片底部描述
   alt: "微调模型——续（Machine Learning 研习之十三）"
   relative: false

---

### 集成方法

微调系统的另一种方法是尝试组合性能最佳的模型。 群体（或“整体”）通常会比最好的单个模型表现得更好，就像```随机森林```比它们所依赖的单个```决策树```表现更好一样，特别是当各个模型犯下不同类型的错误时。 例如，您可以训练和微调 k 最近邻模型，然后创建一个仅预测```随机森林```预测和该模型预测的平均值的集成模型。 

#### 分析最佳模型及其错误

通过检查最佳模型，您通常会获得对问题的深入见解。 例如，```RandomForestRegressor```可以指示每个属性对于做出准确预测的相对重要性：


![](https://qiucodeimg.oss-rg-china-mainland.aliyuncs.com/qiucode2020/1710578836541.png)


让我们按降序对这些重要性分数进行排序，并将它们显示在相应的属性名称旁边：

![](https://qiucodeimg.oss-rg-china-mainland.aliyuncs.com/qiucode2020/1710578876625.png)


有了这些信息，您可能想尝试删除一些不太有用的功能（例如，显然只有一个```ocean_proximity```类别真正有用，因此您可以尝试删除其他功能）。

您还应该查看系统所犯的具体错误，然后尝试了解为什么会犯这些错误，以及如何解决问题：添加额外的功能或删除无信息的功能，清理异常值等。

现在也是一个好时机，可以确保您的模型不仅平均运行良好，而且适用于所有类别的地区，无论是农村还是城市、富裕还是贫穷、北部还是南部、少数民族还是非少数民族等。 每个类别的验证集需要一些工作，但这很重要：如果您的模型在整个地区类别上表现不佳，那么在问题解决之前可能不应该部署它，或者至少不应该使用它 对该类别进行预测，因为它可能弊大于利。

#### 在测试集上评估您的系统

对模型进行一段时间的调整后，您最终会得到一个性能足够好的系统。 您已准备好在测试集上评估最终模型。 这个过程没有什么特别的； 只需从测试集中获取预测变量和标签并运行```Final_model```来转换数据并进行预测，然后评估这些预测：

```python
X_test = strat_test_set.drop("median_house_value", axis=1) 
y_test = strat_test_set["median_house_value"].copy()

final_predictions = final_model.predict(X_test)
final_rmse = mean_squared_error(y_test, final_predictions, squared=False) 

print(final_rmse)  # prints 41424.40026462184 
```

在某些情况下，这样的泛化误差点估计不足以说服您启动：如果它只比当前生产的模型好 0.1% 怎么办？ 您可能想了解这个估计的精确度。 为此，您可以使用 ```scipy.stats.t.interval() ```计算泛化误差的 95% 置信区间。 您会得到从 39,275 到 43,467 的相当大的区间，而您之前的点估计值 41,424 大致位于中间：

![](https://qiucodeimg.oss-rg-china-mainland.aliyuncs.com/qiucode2020/1710578916799.png)


如果您进行了大量的超参数调整，性能通常会比使用交叉验证测量的性能稍差。 这是因为您的系统最终经过微调以在验证数据上表现良好，但在未知数据集上可能表现不佳。 本示例中的情况并非如此，因为```测试 RMSE```低于```验证 RMSE```，但当发生这种情况时，您必须抵制调整超参数以使数字在测试集上看起来不错的诱惑； 这些改进不太可能推广到新数据。

 现在是项目预启动阶段：您需要展示您的解决方案（突出显示您所学到的内容、有效的内容和无效的内容、做出的假设以及系统的局限性），记录所有内容，并使用以下内容创建精美的演示文稿： 清晰的可视化和易于记忆的陈述（例如，“收入中位数是房价的第一预测指标”）。 在这个加州住房示例中，系统的最终性能并不比专家的价格估计好多少，专家的价格估计通常会下降 30%，但启动它可能仍然是一个好主意，特别是如果这样可以释放更多资金 给专家一些时间，以便他们可以从事更有趣、更有成效的任务。

### 启动、监控和维护您的系统

 您现在需要准备好用于生产的解决方案（例如，完善代码、编写文档和测试等）。 然后您可以将模型部署到生产环境。 最基本的方法就是保存您训练的最佳模型，将文件传输到您的生产环境并加载它。 要保存模型，您可以使用 joblib 库，如下所示：

```python
import joblib
joblib.dump(final_model, "my_california_housing_model.pkl")
```

一旦您的模型转移到生产中，您就可以加载并使用它。 为此，您必须首先导入模型依赖的任何自定义类和函数（这意味着将代码转移到生产环境），然后使用 joblib 加载模型并使用它进行预测：

```python
import joblib [...]  # import KMeans, BaseEstimator, TransformerMixin, rbf_kernel, etc.
def column_ratio(X): [...] 
    
def ratio_name(function_transformer, feature_names_in): [...] 
    
class ClusterSimilarity(BaseEstimator, TransformerMixin): [...]
final_model_reloaded = joblib.load("my_california_housing_model.pkl")
new_data = [...]  # some new districts to make predictions for predictions = final_model_reloaded.predict(new_data) 
```

例如，该模型可能会在网站中使用：用户将输入有关新地区的一些数据，然后单击“估计价格”按钮。 这会将包含数据的查询发送到 Web 服务器，服务器将其转发到您的 Web 应用程序，最后您的代码将简单地调用模型的 ```Predict() ```方法（您希望在服务器启动时加载模型，而不是每次都加载模型） 使用该模型）。 或者，您可以将模型包装在专用 Web 服务中，您的 Web 应用程序可以通过 REST API13 查询该模型（见下图）。 这使得您可以更轻松地将模型升级到新版本，而无需中断主应用程序。 它还简化了扩展，因为您可以根据需要启动任意数量的 Web 服务，并在这些 Web 服务之间对来自 Web 应用程序的请求进行负载平衡。 此外，它允许您的 Web 应用程序使用任何编程语言，而不仅仅是 Python。


![](https://qiucodeimg.oss-rg-china-mainland.aliyuncs.com/qiucode2020/1710578959569.png)

另一种流行的策略是将模型部署到云端，例如在 Google 的 Vertex AI（以前称为 ```Google Cloud AI Platform```和 ```Google Cloud ML Engine```）上：只需使用 ```joblib```保存模型并将其上传到 Google Cloud Storage (GCS)， 然后前往 Vertex AI 并创建一个新的模型版本，将其指向 GCS 文件。 就是这样！ 这为您提供了一个简单的 Web 服务，可以为您处理负载平衡和扩展。 它接受包含输入数据（例如，某个地区）的 JSON 请求，并返回包含预测的 JSON 响应。 然后，您可以在您的网站（或您正在使用的任何生产环境）中使用此 Web 服务。 正如您将在第 19 章中看到的，在 ```Vertex AI```上部署 ```TensorFlow```模型与部署 Scikit-Learn 模型没有太大区别。

但部署并不是就此结束。 您还需要编写监控代码来定期检查系统的实时性能，并在性能下降时触发警报。 它可能会很快下降，例如，如果您的基础设施中的某个组件发生故障，但请注意，它也可能会非常缓慢地下降，很容易在很长一段时间内被忽视。 由于模型腐烂，这种情况很常见：如果模型是用去年的数据训练的，它可能无法适应今天的数据。

因此，您需要监控模型的实时表现。 但是，你是怎么做的？ 这得看情况。 在某些情况下，可以从下游指标推断模型的性能。 例如，如果您的模型是推荐系统的一部分，并且它建议用户可能感兴趣的产品，那么很容易监控每天销售的推荐产品数量。 如果这个数字下降（与非推荐产品相比），那么主要的嫌疑就是该型号。 这可能是因为数据管道被破坏，或者模型可能需要根据新数据重新训练。

但是，您可能还需要人工分析来评估模型的性能。 例如，假设您训练了一个```图像分类模型```来检测生产线上的各种产品缺陷。 如果模型性能下降，在数千件有缺陷的产品被运送给您的客户之前，您如何才能收到警报？ 一种解决方案是向人类评分者发送模型分类的所有图片的样本（尤其是模型不太确定的图片）。 根据任务的不同，评估者可能需要是专家，也可能是非专家，例如众包平台（例如 ```Amazon Mechanical Turk```）上的工作人员。 在某些应用程序中，他们甚至可能是用户本身，通过调查或重新调整用途的验证码等方式进行响应。

无论哪种方式，您都需要建立一个监控系统（有或没有人工评估员来评估实时模型），以及所有相关流程来定义发生故障时该做什么以及如何做好准备。 不幸的是，这可能需要大量工作。 事实上，这通常比构建和训练模型要复杂得多。

如果数据不断变化，您将需要定期更新数据集并重新训练模型。 您可能应该尽可能自动化整个过程。 以下是您可以自动化执行的一些操作：

* 定期收集新数据并对其进行标记（例如，使用人工评分者）。
* 编写脚本来训练模型并自动微调超参数。 该脚本可以自动运行，例如每天或每周，具体取决于您的需要。
* 编写另一个脚本，在更新的测试集上评估新模型和之前的模型，如果性能没有下降，则将模型部署到生产环境（如果确实下降，请确保调查原因）。 该脚本可能应该在测试集的各个子集上测试模型的性能，例如贫困地区或富裕地区、农村或城市地区等。

您还应该确保评估模型的输入数据质量。 有时，由于信号质量差（例如，故障传感器发送随机值，或其他团队的输出变得过时），性能会略有下降，但系统的性能可能需要一段时间才能下降到足以触发警报。 如果您监控模型的输入，您可能会更早发现这一点。 例如，如果越来越多的输入缺少某个特征，或者平均值或标准差偏离训练集太远，或者分类特征开始包含新类别，您可以触发警报。

最后，确保保留您创建的每个模型的备份，并拥有快速回滚到以前的模型的流程和工具，以防新模型由于某种原因开始严重失败。 有了备份还可以轻松地将新模型与以前的模型进行比较。 同样，您应该保留数据集的每个版本的备份，以便在新数据集损坏时（例如，如果添加到其中的新数据充满了异常值），您可以回滚到以前的数据集。 备份数据集还允许您根据任何以前的数据集评估任何模型。